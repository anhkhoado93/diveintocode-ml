{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVK7-QKWTYqQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWZWJa5lb8Uz"
      },
      "source": [
        "dftrain = pd.read_csv(\"application_train.csv\")\n",
        "# dftest  = pd.read_csv(\"application_test.csv\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUOcPYC5cHgk"
      },
      "source": [
        "#Problem 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8truHtAcG6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe47a5f-05f7-4ffe-f1c4-c34baf44b528"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "le_count = 0\n",
        "\n",
        "for col in dftrain:\n",
        "    if dftrain[col].dtypes == 'object':        \n",
        "        if len(list(dftrain[col].unique())) <= 2:\n",
        "            le.fit(dftrain[col])\n",
        "            dftrain[col] = le.transform(dftrain[col])  \n",
        "            le_count += 1\n",
        "\n",
        "print('{} columns are label encoded.'.format(le_count))\n",
        "\n",
        "# Choose some data\n",
        "X = dftrain[['DAYS_BIRTH', 'DAYS_EMPLOYED']].values\n",
        "y = dftrain[[\"TARGET\"]].values"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 columns are label encoded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI-sqBVXcWeN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714c862d-683e-4126-a148-c2e232665aff"
      },
      "source": [
        "kf = KFold(n_splits=10)\n",
        "print(\"No of split: %d\" %  kf.get_n_splits(X))\n",
        "\n",
        "for train_index, test_index in kf.split(X):\n",
        "  X_train, X_test = X[train_index], X[test_index]\n",
        "  y_train, y_test = y[train_index], y[test_index]\n",
        "  # Standard Scaling\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(X_train)\n",
        "  X_train = scaler.transform(X_train)\n",
        "  X_test  = scaler.transform(X_test)\n",
        "  # Prediction using random forest classifier\n",
        "  rf = RandomForestClassifier(n_estimators=5)\n",
        "  rf.fit(X_train, y_train)\n",
        "\n",
        "  trainset = rf.score(X_train, y_train)\n",
        "  testset  = rf.score(X_test, y_test)\n",
        "\n",
        "  print(\"Sample score:\\nTrain: {}\\nTest: {}\\n\".format(trainset, testset))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of split: 10\n",
            "Sample score:\n",
            "Train: 0.9732185764509916\n",
            "Test: 0.8980554110301769\n",
            "\n",
            "Sample score:\n",
            "Train: 0.9739557739557739\n",
            "Test: 0.8964911710188287\n",
            "\n",
            "Sample score:\n",
            "Train: 0.9736558751264633\n",
            "Test: 0.8949627654385224\n",
            "\n",
            "Sample score:\n",
            "Train: 0.9738293105940165\n",
            "Test: 0.8931091671815551\n",
            "\n",
            "Sample score:\n",
            "Train: 0.9736956207544443\n",
            "Test: 0.8970439985691522\n",
            "\n",
            "Sample score:\n",
            "Train: 0.9737245266657031\n",
            "Test: 0.8993528665734448\n",
            "\n",
            "Sample score:\n",
            "Train: 0.9733921086862264\n",
            "Test: 0.8984098078111281\n",
            "\n",
            "Sample score:\n",
            "Train: 0.9735547044370574\n",
            "Test: 0.8996780592501057\n",
            "\n",
            "Sample score:\n",
            "Train: 0.9734210145974852\n",
            "Test: 0.8979545380638028\n",
            "\n",
            "Sample score:\n",
            "Train: 0.9734354675531146\n",
            "Test: 0.8997756170531039\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ist8ZOQxli-2"
      },
      "source": [
        "#Problem 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khc1aOpfpD2y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff98624-8f66-4d2f-efea-2a8742586077"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.75, test_size=0.25)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "param = \\\n",
        "{\n",
        "    \"n_estimators\": np.arange(1,5),\n",
        "    \"max_depth\": np.arange(1, 7),\n",
        "    \"criterion\": [\"gini\", \"entropy\"],\n",
        "    \"min_samples_split\": np.arange(1, 30)\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(RandomForestClassifier(), param, cv=5)\n",
        "grid.fit(X_train, y_train)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,...\n",
              "                                              random_state=None, verbose=0,\n",
              "                                              warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': array([1, 2, 3, 4, 5, 6]),\n",
              "                         'min_samples_split': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
              "                         'n_estimators': array([1, 2, 3, 4])},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q97s3OxhquDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "072d81c5-311b-4e2e-9252-97ae3aa8b119"
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': 5,\n",
              " 'min_samples_split': 10,\n",
              " 'n_estimators': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKB0N82Pq1cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df640c9-f131-4246-b5b0-9a245807f5d1"
      },
      "source": [
        "model = grid.best_estimator_\n",
        "model.score(X_test, y_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9201592132989932"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ljbntd0q7Cf"
      },
      "source": [
        "#Problem 3\n",
        "\n",
        "After looking at several Kaggel Notebooks, here is the lists of used methods:\n",
        "\n",
        "- XGBClassifier(n_estimators=500, max_depth=8, random_state=2018)\n",
        "- LogisticRegression(C = 0.0001)\n",
        "- RandomForestClassifier(n_estimators=128, random_state=42, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiVjETIn07JB"
      },
      "source": [
        "#Problem 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5ulnN5y01Pn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9a894dc-d267-4188-edd1-2fd52399c010"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {'C': [0.0001, 0.001, 0.01, 0.1 ,1]}\n",
        "grid_log = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid_log.fit(X_train, y_train)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
              "                                          fit_intercept=True,\n",
              "                                          intercept_scaling=1, l1_ratio=None,\n",
              "                                          max_iter=100, multi_class='auto',\n",
              "                                          n_jobs=None, penalty='l2',\n",
              "                                          random_state=None, solver='lbfgs',\n",
              "                                          tol=0.0001, verbose=0,\n",
              "                                          warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xFENdiM3DRx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b364a1-0900-471c-8987-cb4b297baf5b"
      },
      "source": [
        "grid_log.best_score_"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9189751684071045"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6EDzKdv3TOi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc7f2c7-7da6-4e90-c9c0-3f49dacb0387"
      },
      "source": [
        "grid_log.best_params_"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.0001}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fd6t-Lsq3Z_k"
      },
      "source": [
        "#Problem 5\n",
        "\n",
        "After the comparison, we can see the model selected in problem 4 yield better result."
      ]
    }
  ]
}